{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data set into Python using, e.g., load_wine or genfromtxt, as\n",
    "appropriate. In the case of the USPS dataset, merge the original training\n",
    "and test sets into one dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Wine data and ZIP code data (merge the ZIP code test and train data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9298, 257)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "\n",
    "# 257 columns; column 1 contains the digit id (0-9); other columns are the 256 grayscale values\n",
    "\n",
    "# 7291 rows\n",
    "zc = np.genfromtxt(\"zip.train\", delimiter=' ', dtype=None)\n",
    "\n",
    "# 2007 rows\n",
    "zc2 = np.genfromtxt(\"zip.test\", delimiter=' ')\n",
    "\n",
    "zipcodes = np.concatenate((zc, zc2), axis=0)\n",
    "print(zipcodes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Divide the dataset into a training set and a test set. You may use the\n",
    "function train_test_split. Use your birthday in the format DDMM as\n",
    "random_state (omit leading zeros if any)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split datasets into test and train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 13) (45, 13) (133,) (45,)\n",
      "(9298, 256)\n",
      "(9298,)\n",
      "(6973, 256) (2325, 256) (6973,) (2325,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(X_wine,\n",
    "                                                                        y_wine,\n",
    "                                                                        random_state=308)\n",
    "\n",
    "print(X_train_wine.shape, X_test_wine.shape, y_train_wine.shape, y_test_wine.shape)\n",
    "\n",
    "y_zipcodes = zipcodes[:, 0] # Just target the first column, which contains the labels.\n",
    "X_zipcodes = np.delete(zipcodes, 0, axis=1) # Get all columns except the first one.\n",
    "\n",
    "print(X_zipcodes.shape)\n",
    "print(y_zipcodes.shape)\n",
    "\n",
    "X_train_zipcodes, X_test_zipcodes, y_train_zipcodes, y_test_zipcodes = train_test_split(X_zipcodes,\n",
    "                                                                                       y_zipcodes,\n",
    "                                                                                       random_state=308)\n",
    "\n",
    "print(X_train_zipcodes.shape, X_test_zipcodes.shape, y_train_zipcodes.shape, y_test_zipcodes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using cross-validation and the training set only, estimate the generalization accuracy of the SVM with the default values of the parameters. You may use the function cross_val_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:\n",
      "Wine: [0.42222222 0.4        0.37209302]\n",
      "ZIP Codes: [0.96005155 0.96385542 0.96510125]\n",
      "Avg. Cross Validation Scores:\n",
      "Wine: 0.39810508182601206\n",
      "ZIP Codes: 0.9630027391799795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "# Default value for cv is changing from 3 to 5, so I explicitly set cv to 3 to remove the warning\n",
    "cv_score_wine = cross_val_score(svm, X_train_wine, y_train_wine, cv=3)\n",
    "cv_score_zipcodes = cross_val_score(svm, X_train_zipcodes, y_train_zipcodes, cv=3)\n",
    "\n",
    "print(\"Cross Validation Scores:\\nWine: {}\\nZIP Codes: {}\".format(cv_score_wine, cv_score_zipcodes))\n",
    "print(\"Avg. Cross Validation Scores:\\nWine: {}\\nZIP Codes: {}\".format(cv_score_wine.mean(), cv_score_zipcodes.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Error Rate:\n",
      "Wine: 0.6018949181739879\n",
      "ZIP Codes: 0.03699726082002053\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg. Error Rate:\\nWine: {}\\nZIP Codes: {}\".format(1 - cv_score_wine.mean(), 1 - cv_score_zipcodes.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Find the test error rate of the SVM with the default values of parameters, compare it with the estimate obtained in the previous task (task 3), and write your observations in a markdown cell of your Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error Rates:\n",
      "Wine: 0.3555555555555555\n",
      "ZIP Codes: 0.03741935483870973\n"
     ]
    }
   ],
   "source": [
    "svm1 = SVC().fit(X_train_wine, y_train_wine)\n",
    "svm2 = SVC().fit(X_train_zipcodes, y_train_zipcodes)\n",
    "\n",
    "# Test accuracy for wine\n",
    "svm_score_wine = svm1.score(X_test_wine, y_test_wine)\n",
    "# Test accuracy for ZIP codes\n",
    "svm_score_zipcodes = svm2.score(X_test_zipcodes, y_test_zipcodes)\n",
    "\n",
    "print(\"Test Error Rates:\\nWine: {}\\nZIP Codes: {}\".format(1 - svm_score_wine, 1 - svm_score_zipcodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Wine: 0.6444444444444445\n",
      "ZIP Codes: 0.9625806451612903\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\\nWine: {}\\nZIP Codes: {}\".format(svm_score_wine, svm_score_zipcodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Estimate of the generalization accuracy of SVM\n",
    "\n",
    "> Predicted Error Rates (Using Cross-Validation):\n",
    "* Wine: 0.6018949181739879 = **60.2%**\n",
    "* ZIP codes: 0.03699726082002053 = **3.7%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test Error Rates:\n",
    "\n",
    "> Actual Test Error Rates:\n",
    "* Wine: 0.3555555555555555 = **35.6%**\n",
    "* ZIP codes: 0.03741935483870973 = **3.7%**\n",
    "\n",
    "As we can see, the predicted and actual test error rate for the Wine dataset (using SVM with the default parameters) is quite different. In fact, the actual test error rate was almost half of that predicted using cross-validation.\n",
    "\n",
    "On the other hand, the predicted and actual test error rates for the ZIP codes dataset were almost identical (both were approximately 3.7%).\n",
    "\n",
    "This means that the predicted test error rate for the ZIP codes dataset was accuarate, while the one for the Wine dataset was not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a pipeline for SVM involving data normalization and SVC, and use grid search and cross-validation to tune parameters C and gamma for the pipeline, avoiding data snooping and data leakage. You may use the scikit-learn class GridSearchCV. Experiment with different ways of doing normalization (such as StandardScaler, MinMaxScaler, RobustScaler, and Normalizer). Which ways are appropriate for either dataset? (The answer, which should be written in your Jupyter notebook, may depend on the results that you obtain for the next task.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Fit the GridSearchCV object of task 5 to the training set and use it to predict the test labels. Write the resulting test accuracy in your Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 & 6 Create pipeline for SVN; use grid search to tune parameters; fit GridSearchCV object to training set and predict test set labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline and GridSearchCV objects for Wine Dataset; fit them and get accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid: ('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1)))\n",
      "Best cross-validation accuracy: 0.9924812030075187\n",
      "Test set score: 1.0\n",
      "Best parameters: {'svc__C': 1, 'svc__gamma': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid: ('normalizer', Normalizer(copy=True, norm='l2'))\n",
      "Best cross-validation accuracy: 0.9172932330827067\n",
      "Test set score: 0.9555555555555556\n",
      "Best parameters: {'svc__C': 100, 'svc__gamma': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid: ('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True))\n",
      "Best cross-validation accuracy: 0.9849624060150376\n",
      "Test set score: 1.0\n",
      "Best parameters: {'svc__C': 10, 'svc__gamma': 0.01}\n",
      "\n",
      "Grid: ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))\n",
      "Best cross-validation accuracy: 0.9849624060150376\n",
      "Test set score: 1.0\n",
      "Best parameters: {'svc__C': 1, 'svc__gamma': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, RobustScaler, StandardScaler\n",
    "\n",
    "param_grid = {'svc__C': [0.01, 0.1, 1, 10, 100],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "minmax_pipe = make_pipeline(MinMaxScaler(), SVC())\n",
    "norm_pipe = make_pipeline(Normalizer(), SVC())\n",
    "robust_pipe = make_pipeline(RobustScaler(), SVC())\n",
    "standard_pipe = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "minmax_grid = GridSearchCV(minmax_pipe, param_grid=param_grid, cv=5)\n",
    "norm_grid = GridSearchCV(norm_pipe, param_grid=param_grid, cv=5)\n",
    "robust_grid = GridSearchCV(robust_pipe, param_grid=param_grid, cv=5)\n",
    "standard_grid = GridSearchCV(standard_pipe, param_grid=param_grid, cv=5)\n",
    "\n",
    "grids = [minmax_grid, norm_grid, robust_grid, standard_grid]\n",
    "best_grids_wine = []\n",
    "\n",
    "for grid in grids:\n",
    "    \n",
    "    grid.fit(X_train_wine, y_train_wine)\n",
    "    print(\"\\nGrid:\", grid.estimator.steps[0])\n",
    "    print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
    "    print(\"Test set score:\", grid.score(X_test_wine, y_test_wine))\n",
    "    print(\"Best parameters:\", grid.best_params_)\n",
    "    best_grids_wine.append(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipelines and GridSearchCV objects for ZIP codes dataset; fit them and get accuracies. **Takes ages to run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid: ('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1)))\n",
      "Best cross-validation accuracy: 0.9716047612218557\n",
      "Test set score: 0.9681720430107527\n",
      "Best parameters: {'svc__C': 10, 'svc__gamma': 0.01}\n",
      "\n",
      "Grid: ('normalizer', Normalizer(copy=True, norm='l2'))\n",
      "Best cross-validation accuracy: 0.9747597877527606\n",
      "Test set score: 0.9703225806451613\n",
      "Best parameters: {'svc__C': 10, 'svc__gamma': 1}\n",
      "\n",
      "Grid: ('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True))\n",
      "Best cross-validation accuracy: 0.8792485300444572\n",
      "Test set score: 0.8713978494623655\n",
      "Best parameters: {'svc__C': 100, 'svc__gamma': 0.001}\n",
      "\n",
      "Grid: ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))\n",
      "Best cross-validation accuracy: 0.9670156317223577\n",
      "Test set score: 0.9625806451612903\n",
      "Best parameters: {'svc__C': 10, 'svc__gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "minmax_pipe = make_pipeline(MinMaxScaler(), SVC())\n",
    "norm_pipe = make_pipeline(Normalizer(), SVC())\n",
    "robust_pipe = make_pipeline(RobustScaler(), SVC())\n",
    "standard_pipe = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "minmax_grid = GridSearchCV(minmax_pipe, param_grid=param_grid, cv=5)\n",
    "norm_grid = GridSearchCV(norm_pipe, param_grid=param_grid, cv=5)\n",
    "robust_grid = GridSearchCV(robust_pipe, param_grid=param_grid, cv=5)\n",
    "standard_grid = GridSearchCV(standard_pipe, param_grid=param_grid, cv=5)\n",
    "\n",
    "grids = [minmax_grid, norm_grid, robust_grid, standard_grid]\n",
    "best_grids_zipcodes = []\n",
    "\n",
    "for grid in grids:\n",
    "    \n",
    "    grid.fit(X_train_zipcodes, y_train_zipcodes)\n",
    "    print(\"\\nGrid:\", grid.estimator.steps[0])\n",
    "    print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
    "    print(\"Test set score:\", grid.score(X_test_zipcodes, y_test_zipcodes))\n",
    "    print(\"Best parameters:\", grid.best_params_)\n",
    "    best_grids_zipcodes.append(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 & 6 Results:\n",
    "\n",
    "### Wine Dataset:\n",
    "\n",
    "minmaxscaler:\n",
    "* Best cross-validation accuracy: 0.9924812030075187\n",
    "* Test set score: 1.0\n",
    "* Test Error Rate: 0\n",
    "* Best Parameters for SVM {'svc__C': 1, 'svc__gamma': 1}\n",
    "\n",
    "normalizer:\n",
    "* Best cross-validation accuracy: 0.9172932330827067\n",
    "* Test set score: 0.9555555555555556\n",
    "* Test Error Rate: 0.04444444444\n",
    "* Best parameters for SVM {'svc__C': 100, 'svc__gamma': 100}\n",
    "\n",
    "robustscaler:\n",
    "* Best cross-validation accuracy: 0.9849624060150376\n",
    "* Test set score: 1.0\n",
    "* Test Error Rate: 0\n",
    "* Best parameters for SVM {'svc__C': 10, 'svc__gamma': 0.01}\n",
    "\n",
    "standardscaler:\n",
    "* Best cross-validation accuracy: 0.9849624060150376\n",
    "* Test set score: 1.0\n",
    "* Test Error Rate: 0\n",
    "* Best parameters for SVM {'svc__C': 1, 'svc__gamma': 0.1}\n",
    "\n",
    "> For the wine dataset, minmaxscaler had the highest cross-validation accuracy out of them all (~ 99.2%); robustscaler and standard scaler both had the next highest (~ 98.5%) while normalizer had the worst (~ 91.7%).\n",
    "In terms of accuracy on the test set, minmaxscaler, robustscaler and standardscaler all had 100% accuracy, while the normalizer only had ~ 95.6% accuracy. From this we can see that the minmaxscaler (with SVM parameters C=1 and gamma=1) is the best one to use (as it had the highest cross-validation accuracy and test set accuracy), although robustscaler and standardscaler would be suitable alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZIP Code Dataset:\n",
    "\n",
    "minmaxscaler:\n",
    "* Best cross-validation accuracy: 0.9716047612218557\n",
    "* Test set score: 0.9681720430107527\n",
    "* Test Error Rate: 0.03182795698\n",
    "* Best Parameters for SVM {'svc__C': 10, 'svc__gamma': 0.01}\n",
    "\n",
    "normalizer:\n",
    "* Best cross-validation accuracy: 0.9747597877527606\n",
    "* Test set score: 0.9703225806451613\n",
    "* Test Error Rate: 0.02967741935\n",
    "* Best parameters for SVM {'svc__C': 10, 'svc__gamma': 1}\n",
    "\n",
    "robustscaler:\n",
    "* Best cross-validation accuracy: 0.8792485300444572\n",
    "* Test set score: 0.8713978494623655\n",
    "* Test Error Rate: 0.12860215053\n",
    "* Best parameters for SVM {'svc__C': 100, 'svc__gamma': 0.001}\n",
    "\n",
    "standardscaler:\n",
    "* Best cross-validation accuracy: 0.9670156317223577\n",
    "* Test set score: 0.9625806451612903\n",
    "* Test Error Rate: 0.03741935483\n",
    "* Best parameters for SVM {'svc__C': 10, 'svc__gamma': 0.001}\n",
    "\n",
    "> For the ZIP code dataset, the normalizer had the highest cross-validation accuracy (~ 97.5%) and the highest test set score (~ 97.0%), making it the best way of normalising this dataset out of the 4. For cross-validation accuracy and test set accuracy, minmaxscaler came second with ~ 97.1% and ~ 96.8% respectively, followed by standard scaler, which had ~ 96.7% and ~ 96.2% respectively. robustscaler had the worst accuracies, with a cross-validation accuracy of ~ 87.9% and test set accuracy of ~ 87.1%. In this case, normalizer is the best to use as it had the highest cross-validation accuracy and highest test set accuracy. minmaxscaler or standardscaler could be suitable alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Get conformity scores for Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: [  8  10  11  13  18  22  39  44  56  60  64  65  67  70  71  84  86  98\n",
      " 103 105 108 115 116 121 123 124 128 132 135 136 137 146 148 153 166 168]\n",
      "The rest of the training set: [  0   1   2   3   4   5   6   7   9  12  14  15  16  17  19  20  21  23\n",
      "  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  40  41  42\n",
      "  43  45  46  47  48  49  50  51  52  53  54  55  57  58  59  61  62  63\n",
      "  66  68  69  72  73  74  75  76  77  78  79  80  81  82  83  85  87  88\n",
      "  89  90  91  92  93  94  95  96  97  99 100 101 102 104 106 107 109 110\n",
      " 111 112 113 114 117 118 119 120 122 125 126 127 129 130 131 133 134 138\n",
      " 139 140 141 142 143 144 145 147 149 150 151 152 154 155 156 157 158 159\n",
      " 160 161 162 163 164 165 167 169 170 171 172 173 174 175 176 177]\n",
      "1.0\n",
      "Current fold: [  0   4   5   9  15  19  21  27  28  30  36  41  53  66  69  72  75  79\n",
      "  83  85  87  96  97 100 101 107 112 113 114 125 130 138 139 152 163 167]\n",
      "The rest of the training set: [  1   2   3   6   7   8  10  11  12  13  14  16  17  18  20  22  23  24\n",
      "  25  26  29  31  32  33  34  35  37  38  39  40  42  43  44  45  46  47\n",
      "  48  49  50  51  52  54  55  56  57  58  59  60  61  62  63  64  65  67\n",
      "  68  70  71  73  74  76  77  78  80  81  82  84  86  88  89  90  91  92\n",
      "  93  94  95  98  99 102 103 104 105 106 108 109 110 111 115 116 117 118\n",
      " 119 120 121 122 123 124 126 127 128 129 131 132 133 134 135 136 137 140\n",
      " 141 142 143 144 145 146 147 148 149 150 151 153 154 155 156 157 158 159\n",
      " 160 161 162 164 165 166 168 169 170 171 172 173 174 175 176 177]\n",
      "0.9722222222222222\n",
      "Current fold: [  1   6   7  17  23  29  34  42  45  48  49  57  74  77  81  82  88  89\n",
      "  90  91 102 106 109 110 111 129 140 145 154 161 162 165 171 173 174 177]\n",
      "The rest of the training set: [  0   2   3   4   5   8   9  10  11  12  13  14  15  16  18  19  20  21\n",
      "  22  24  25  26  27  28  30  31  32  33  35  36  37  38  39  40  41  43\n",
      "  44  46  47  50  51  52  53  54  55  56  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  75  76  78  79  80  83  84  85  86  87\n",
      "  92  93  94  95  96  97  98  99 100 101 103 104 105 107 108 112 113 114\n",
      " 115 116 117 118 119 120 121 122 123 124 125 126 127 128 130 131 132 133\n",
      " 134 135 136 137 138 139 141 142 143 144 146 147 148 149 150 151 152 153\n",
      " 155 156 157 158 159 160 163 164 166 167 168 169 170 172 175 176]\n",
      "1.0\n",
      "Current fold: [  2   3  12  16  20  25  33  35  38  43  46  50  54  55  59  61  68  73\n",
      "  78  92  93  94 104 119 122 127 131 134 142 147 155 156 158 159 164]\n",
      "The rest of the training set: [  0   1   4   5   6   7   8   9  10  11  13  14  15  17  18  19  21  22\n",
      "  23  24  26  27  28  29  30  31  32  34  36  37  39  40  41  42  44  45\n",
      "  47  48  49  51  52  53  56  57  58  60  62  63  64  65  66  67  69  70\n",
      "  71  72  74  75  76  77  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  95  96  97  98  99 100 101 102 103 105 106 107 108 109 110 111 112\n",
      " 113 114 115 116 117 118 120 121 123 124 125 126 128 129 130 132 133 135\n",
      " 136 137 138 139 140 141 143 144 145 146 148 149 150 151 152 153 154 157\n",
      " 160 161 162 163 165 166 167 168 169 170 171 172 173 174 175 176 177]\n",
      "0.9714285714285714\n",
      "Current fold: [ 14  24  26  31  32  37  40  47  51  52  58  62  63  76  80  95  99 117\n",
      " 118 120 126 133 141 143 144 149 150 151 157 160 169 170 172 175 176]\n",
      "The rest of the training set: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18\n",
      "  19  20  21  22  23  25  27  28  29  30  33  34  35  36  38  39  41  42\n",
      "  43  44  45  46  48  49  50  53  54  55  56  57  59  60  61  64  65  66\n",
      "  67  68  69  70  71  72  73  74  75  77  78  79  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  96  97  98 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 119 121 122 123 124 125 127 128\n",
      " 129 130 131 132 134 135 136 137 138 139 140 142 145 146 147 148 152 153\n",
      " 154 155 156 158 159 161 162 163 164 165 166 167 168 171 173 174 177]\n",
      "1.0\n",
      "[array([[ 2.22902918,  0.89237237, -0.21073621],\n",
      "       [ 2.24132571,  0.85930367, -0.21809348],\n",
      "       [ 2.23477633,  0.87719246, -0.21423468],\n",
      "       [ 2.20533016,  0.94684828, -0.19527267],\n",
      "       [ 2.21857847,  0.88894491, -0.19474014],\n",
      "       [ 2.24390552,  0.91489788, -0.23484708],\n",
      "       [ 2.22642163,  0.87317071, -0.20019515],\n",
      "       [ 2.21985065,  1.1069752 , -0.23557871],\n",
      "       [ 2.2397688 ,  0.86678286, -0.21826799],\n",
      "       [-0.21766935,  2.23265262,  0.89994881],\n",
      "       [-0.20398096,  2.24821901,  0.80915571],\n",
      "       [ 1.04841579,  2.21859541, -0.22493579],\n",
      "       [ 0.83259933,  2.24816734, -0.21859174],\n",
      "       [-0.21643725,  2.18635061,  1.12285513],\n",
      "       [ 1.05851446,  2.20150545, -0.21174404],\n",
      "       [ 0.84750221,  2.23713782, -0.2061976 ],\n",
      "       [-0.21092459,  2.25346515,  0.80269743],\n",
      "       [ 1.03005731,  2.21630137, -0.22023675],\n",
      "       [-0.22470602,  2.26081133,  0.79853832],\n",
      "       [-0.20378967,  2.24034217,  0.83238584],\n",
      "       [ 0.79577354,  2.25880713, -0.21802738],\n",
      "       [ 0.80018687,  2.24309313, -0.18163504],\n",
      "       [ 0.79245248,  2.25826141, -0.21386669],\n",
      "       [ 0.89379913,  2.19061123, -0.15488637],\n",
      "       [ 0.95130646,  2.19345291, -0.18263449],\n",
      "       [ 0.89228868,  2.22285353, -0.20208659],\n",
      "       [ 0.80557119,  2.25598496, -0.21877701],\n",
      "       [-0.23261669,  0.98794381,  2.23374586],\n",
      "       [-0.23239346,  1.07406239,  2.2228351 ],\n",
      "       [-0.22838853,  1.02106332,  2.22611153],\n",
      "       [-0.22448483,  1.06465551,  2.21520195],\n",
      "       [-0.2242372 ,  0.96766315,  2.22794288],\n",
      "       [-0.22696947,  0.84724651,  2.24957707],\n",
      "       [-0.21971055,  0.90252748,  2.23374008],\n",
      "       [-0.21251869,  0.83746042,  2.24350349],\n",
      "       [-0.21138797,  0.83473643,  2.24364968]]), array([[ 2.24509164,  0.84991639, -0.22066334],\n",
      "       [ 2.20430886,  1.10033695, -0.22274298],\n",
      "       [ 2.24755554,  0.82464171, -0.21325526],\n",
      "       [ 2.24185437,  0.85564974, -0.21759254],\n",
      "       [ 2.24470711,  0.83890853, -0.21537477],\n",
      "       [ 2.23736811,  0.885266  , -0.22028612],\n",
      "       [ 2.2046753 ,  1.08988835, -0.22072385],\n",
      "       [ 2.21576024,  0.96683627, -0.21099267],\n",
      "       [ 2.24064435,  0.94454612, -0.23519874],\n",
      "       [ 2.22731394,  0.9383257 , -0.21906266],\n",
      "       [ 2.22288856,  1.00390393, -0.22332053],\n",
      "       [ 2.20345658,  0.99132172, -0.20208967],\n",
      "       [ 2.24886679,  0.82653263, -0.21683437],\n",
      "       [ 1.04738899,  2.20794525, -0.21530335],\n",
      "       [ 0.84070449,  2.22761446, -0.18437245],\n",
      "       [-0.18484162,  2.21558516,  0.87682496],\n",
      "       [-0.22224698,  2.25026238,  0.83234217],\n",
      "       [ 0.96093907,  2.23100032, -0.22665308],\n",
      "       [-0.22017877,  1.13698174,  2.1850658 ],\n",
      "       [ 0.87606645,  2.24418219, -0.22741629],\n",
      "       [ 0.81079605,  2.24903853, -0.20714906],\n",
      "       [-0.19544566,  2.21018915,  0.92517936],\n",
      "       [ 0.84773101,  2.25138229, -0.2300223 ],\n",
      "       [ 0.88609077,  2.23993552, -0.22403779],\n",
      "       [-0.20149748,  2.24199796,  0.82381361],\n",
      "       [-0.21575492,  2.22766727,  0.91926757],\n",
      "       [-0.16347698,  2.21250085,  0.85224388],\n",
      "       [ 0.78287165,  2.25869082, -0.20499178],\n",
      "       [ 0.81547225,  2.2503306 , -0.21325097],\n",
      "       [ 0.83069942,  2.25269281, -0.22585695],\n",
      "       [-0.21666883,  1.16590171,  2.15473002],\n",
      "       [-0.2355813 ,  0.98005472,  2.23737232],\n",
      "       [-0.21812357,  1.09813135,  2.1987104 ],\n",
      "       [-0.22297102,  1.06895262,  2.21254054],\n",
      "       [-0.2275977 ,  0.91814281,  2.23749345],\n",
      "       [-0.23020989,  0.85549535,  2.24995082]]), array([[ 2.23151238,  0.99895799, -0.23141475],\n",
      "       [ 2.25329045,  0.82149238, -0.22264564],\n",
      "       [ 2.25030878,  0.82777644, -0.22018148],\n",
      "       [ 2.23384193,  0.88395297, -0.21497468],\n",
      "       [ 2.22559119,  1.1028547 , -0.23917329],\n",
      "       [ 2.24188717,  0.91314838, -0.23210133],\n",
      "       [ 2.23982413,  0.90321126, -0.22769881],\n",
      "       [ 2.24576091,  0.86075554, -0.22542169],\n",
      "       [ 2.23997355,  0.82330756, -0.19685595],\n",
      "       [ 2.24222199,  0.85683381, -0.21861562],\n",
      "       [ 2.24341591,  0.83883131, -0.21303868],\n",
      "       [ 2.25235751,  0.83886256, -0.22853378],\n",
      "       [ 1.01369636,  2.21878682, -0.22044902],\n",
      "       [-0.2109396 ,  2.22590529,  0.90831742],\n",
      "       [ 1.12761241,  2.21870339, -0.23885715],\n",
      "       [ 0.80200311,  2.25359219, -0.2106578 ],\n",
      "       [-0.19331089,  2.24206014,  0.81341458],\n",
      "       [ 0.80262641,  2.25432063, -0.21286701],\n",
      "       [-0.22185068,  2.25103972,  0.8284369 ],\n",
      "       [-0.22256587,  2.24726241,  0.84554462],\n",
      "       [ 0.91013339,  2.22921727, -0.21564929],\n",
      "       [ 0.82803804,  2.24915074, -0.21815322],\n",
      "       [ 1.00618742,  2.23540449, -0.23594562],\n",
      "       [ 0.83637584,  2.23236513, -0.19071404],\n",
      "       [ 0.81450444,  2.24785311, -0.20730051],\n",
      "       [-0.19575277,  2.2110223 ,  0.92259078],\n",
      "       [-0.22368409,  1.03746804,  2.21891782],\n",
      "       [-0.22013736,  0.92616855,  2.23011043],\n",
      "       [-0.23826731,  1.10683196,  2.22349175],\n",
      "       [-0.21424404,  0.88493774,  2.23311806],\n",
      "       [-0.22784261,  1.03938478,  2.22317146],\n",
      "       [-0.23582561,  0.9226592 ,  2.24374335],\n",
      "       [-0.24092743,  0.93780719,  2.24645193],\n",
      "       [-0.21888363,  0.84978255,  2.24403554],\n",
      "       [-0.21627316,  0.82479282,  2.24906376],\n",
      "       [-0.22497053,  0.84071227,  2.24981821]]), array([[ 2.24345961,  0.8993244 , -0.23158906],\n",
      "       [ 2.22933961,  0.8612461 , -0.19958406],\n",
      "       [ 2.24966504,  0.84215977, -0.22526879],\n",
      "       [ 2.24332287,  0.82461883, -0.20477861],\n",
      "       [ 2.22825709,  0.96146161, -0.22374082],\n",
      "       [ 1.13461306,  2.16223147, -0.20637615],\n",
      "       [ 2.22326066,  0.89955512, -0.2049802 ],\n",
      "       [ 2.2330879 ,  1.03298571, -0.23629299],\n",
      "       [ 2.19291092,  1.15217461, -0.22961386],\n",
      "       [ 2.18165172,  1.07984772, -0.20066782],\n",
      "       [ 2.24728672,  0.85383479, -0.22556099],\n",
      "       [ 2.19313876,  1.07458466, -0.20829735],\n",
      "       [ 2.23878579,  0.86357416, -0.21566084],\n",
      "       [ 2.23085622,  0.91159488, -0.21806551],\n",
      "       [-0.21465801,  2.23162491,  0.89364664],\n",
      "       [-0.22626155,  2.19272533,  1.14203944],\n",
      "       [-0.16626124,  2.17523143,  0.96610422],\n",
      "       [ 1.00548377,  2.20310515, -0.20395064],\n",
      "       [ 0.84207458,  2.2270611 , -0.18427536],\n",
      "       [-0.2219557 ,  2.2325335 ,  0.92033289],\n",
      "       [ 0.83881814,  2.25425483, -0.23167449],\n",
      "       [ 0.81498972,  2.2524337 , -0.21730999],\n",
      "       [ 0.90947584,  2.2401821 , -0.22934832],\n",
      "       [ 0.81911586,  2.25044691, -0.21575738],\n",
      "       [-0.18939989,  2.23182001,  0.83606436],\n",
      "       [-0.2143748 ,  2.23960702,  0.85666976],\n",
      "       [-0.2290936 ,  0.95273844,  2.23421448],\n",
      "       [-0.22250146,  1.14742527,  2.18281418],\n",
      "       [-0.22606091,  0.94789394,  2.23209728],\n",
      "       [-0.22578004,  0.84469979,  2.24940303],\n",
      "       [-0.22119853,  0.88671576,  2.23775186],\n",
      "       [-0.21629328,  0.85713443,  2.24069198],\n",
      "       [-0.16909849,  1.09749576,  2.12708973],\n",
      "       [-0.18489325,  1.00913266,  2.18300748],\n",
      "       [-0.22121871,  0.84775935,  2.24593203]]), array([[ 2.23277784,  0.85549459, -0.2025961 ],\n",
      "       [ 2.22015536,  1.13457848, -0.24131132],\n",
      "       [ 2.24644696,  0.88236667, -0.23204921],\n",
      "       [ 2.24332767,  0.8534767 , -0.21914393],\n",
      "       [ 2.22495435,  1.09833935, -0.23793451],\n",
      "       [ 2.20883929,  1.09300889, -0.22456148],\n",
      "       [ 2.22989565,  0.98345052, -0.22819115],\n",
      "       [ 2.23781074,  0.90985423, -0.22645776],\n",
      "       [ 2.24721705,  0.87475571, -0.23136088],\n",
      "       [ 2.23873685,  0.87228705, -0.21849491],\n",
      "       [ 2.23783816,  0.8622072 , -0.21368326],\n",
      "       [ 0.87431763,  2.22369336, -0.19644056],\n",
      "       [ 0.84432557,  2.24717757, -0.22195144],\n",
      "       [ 0.81485665,  2.24467323, -0.20054771],\n",
      "       [ 0.78816208,  2.26595938, -0.22929419],\n",
      "       [ 0.93179289,  2.20707848, -0.19344775],\n",
      "       [ 0.85788924,  2.24906803, -0.22957492],\n",
      "       [ 0.80499234,  2.25766133, -0.2220443 ],\n",
      "       [-0.21793432,  2.20018947,  1.09265437],\n",
      "       [ 0.93093582,  2.23996697, -0.23259264],\n",
      "       [ 0.82272637,  2.24480377, -0.2065562 ],\n",
      "       [-0.21055622,  1.04605458,  2.20285148],\n",
      "       [-0.18340609,  0.957985  ,  2.19253929],\n",
      "       [-0.19514144,  1.04068089,  2.18669054],\n",
      "       [-0.17742021,  0.90531244,  2.20182601],\n",
      "       [-0.21423275,  0.85001121,  2.24117148],\n",
      "       [-0.20681714,  0.87510716,  2.23025818],\n",
      "       [-0.21404214,  0.88831147,  2.23226781],\n",
      "       [-0.22630967,  0.89915148,  2.23939326],\n",
      "       [-0.2297458 ,  0.952998  ,  2.23477357],\n",
      "       [-0.1763262 ,  0.84709593,  2.22111847],\n",
      "       [-0.23330761,  1.07878356,  2.22306666],\n",
      "       [-0.20954509,  0.82938463,  2.24423786],\n",
      "       [-0.19958712,  0.82910363,  2.23928722],\n",
      "       [-0.21263249,  0.83768992,  2.24350306]])]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Best estimator for Wine based on task 5.\n",
    "minmax_pipe = make_pipeline(MinMaxScaler(), SVC(C=1, gamma=1))\n",
    "\n",
    "kf = KFold(shuffle=True, random_state=308, n_splits=5)\n",
    "\n",
    "# This will contain the conformity scores for each fold\n",
    "conformity_scores = []\n",
    "actual_labels = []\n",
    "\n",
    "folds = []\n",
    "\n",
    "for rest_index, fold_index in kf.split(wine.data):\n",
    "    print(\"Current fold:\", fold_index)\n",
    "    print(\"The rest of the training set:\", rest_index)\n",
    "    \n",
    "    X_rest, X_fold = wine.data[rest_index], wine.data[fold_index]\n",
    "    y_rest, y_fold = wine.target[rest_index], wine.target[fold_index]\n",
    "    \n",
    "    actual_labels.append(y_fold)\n",
    "    \n",
    "    minmax_pipe.fit(X_rest,y_rest)\n",
    "    \n",
    "    conformity_scores.append(minmax_pipe.decision_function(X_fold))\n",
    "    print(minmax_pipe.score(X_fold,y_fold))\n",
    "\n",
    "\n",
    "print(conformity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
