{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load ```scikit-learn``` diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - Age\n",
      "      - Sex\n",
      "      - Body mass index\n",
      "      - Average blood pressure\n",
      "      - S1\n",
      "      - S2\n",
      "      - S3\n",
      "      - S4\n",
      "      - S5\n",
      "      - S6\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "sk_diabetes = load_diabetes()\n",
    "print(sk_diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split ```scikit-learn``` Data Into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331, 10) (111, 10) (331,) (111,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = sk_diabetes.data\n",
    "y = sk_diabetes.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=308)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training and Test Set R<sup>2</sup> for Lasso Model With ```scikit-learn``` Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng R^2: 0.392352\n",
      "Test R^2: 0.343602\n",
      "Number of features being used: 3\n",
      "Names of features being used:\n",
      "bmi\n",
      "bp\n",
      "s5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "\n",
    "# performance/score of a regressor is evaluated using R^2.\n",
    "# Train R^2\n",
    "print(\"Trainng R^2: %f\" % lasso.score(X_train, y_train))\n",
    "# Test R^2\n",
    "print(\"Test R^2: %f\" % lasso.score(X_test, y_test))\n",
    "\n",
    "# Number of coefficients != 0 will tell us how many features are being used\n",
    "features_used = lasso.coef_ != 0\n",
    "print(\"Number of features being used: %d\" % np.sum(features_used))\n",
    "\n",
    "all_features = list(sk_diabetes.feature_names)\n",
    "\n",
    "print(\"Names of features being used:\")\n",
    "for feature, used in zip(all_features, features_used):\n",
    "    if used:\n",
    "        print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Answers\n",
    "* Training R<sup>2</sup> = 0.392352\n",
    "* Test R<sup>2</sup> = 0.343602\n",
    "* No. of features used = 3 (out of 10)\n",
    "* Names of features being used:\n",
    "    * bmi\n",
    "    * bp\n",
    "    * s5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Read and Load Original Diabetes Data From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 11) (442, 10) (442,)\n"
     ]
    }
   ],
   "source": [
    "# Read diabetes data from file.\n",
    "# First line is headers so we dont include that with the data.\n",
    "\n",
    "import numpy as np\n",
    "diabetes = np.genfromtxt(\"diabetes.data\", delimiter='\\t')[1:]\n",
    "\n",
    "y = diabetes[:, -1] # Target, last column.\n",
    "X = diabetes[:, :-1] # Data, all columns except last.\n",
    "\n",
    "print(diabetes.shape, X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split Original Diabetes Data Into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=308)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training and Test Set R<sup>2</sup> for Lasso Model with Original Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng R^2: 0.532342\n",
      "Test R^2: 0.423408\n",
      "Number of features being used: 9\n",
      "Names of features being used:\n",
      "age\n",
      "sex\n",
      "bmi\n",
      "bp\n",
      "s2\n",
      "s3\n",
      "s4\n",
      "s5\n",
      "s6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "\n",
    "# performance/score of a regressor is evaluated using R^2.\n",
    "# Train R^2\n",
    "print(\"Trainng R^2: %f\" % lasso.score(X_train, y_train))\n",
    "# Test R^2\n",
    "print(\"Test R^2: %f\" % lasso.score(X_test, y_test))\n",
    "\n",
    "# Number of coefficients != 0 will tell us how many features are being used\n",
    "features_used = lasso.coef_ != 0\n",
    "print(\"Number of features being used: %d\" % np.sum(features_used))\n",
    "\n",
    "print(\"Names of features being used:\")\n",
    "for feature, used in zip(all_features, features_used):\n",
    "    if used:\n",
    "        print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Answers\n",
    "* Training R<sup>2</sup> = 0.532342\n",
    "* Test R<sup>2</sup> = 0.423408\n",
    "* No. of features used = 9 (out of 10)\n",
    "* Names of features being used:\n",
    "    * age\n",
    "    * sex\n",
    "    * bmi\n",
    "    * bp\n",
    "    * s2\n",
    "    * s3\n",
    "    * s4\n",
    "    * s5\n",
    "    * s6\n",
    "    \n",
    "> The performance of lasso on this dataset is better than the one from the ```scikit-learn``` version, which can be see from the higher R<sup>2</sup> values for the training and test sets. We can also see that for the current dataset almost all of the features are being used, whereas very few were used in the previous one (9 out of 10 are being used for the current dataset, while only 3 out of 10 were used in the previous one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Preprocess Training and Test Sets Using ```StandardScaler```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Instantiate our scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply same scaler to training and test set to preprocess them in the same way\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training and Test Set R<sup>2</sup> for Lasso Model With Preprocessed Original Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng R^2: 0.534242\n",
      "Test R^2: 0.419899\n",
      "Number of features being used: 7\n",
      "Names of features being used:\n",
      "sex\n",
      "bmi\n",
      "bp\n",
      "s1\n",
      "s3\n",
      "s4\n",
      "s5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso().fit(X_train_scaled, y_train)\n",
    "\n",
    "# performance/score of a regressor is evaluated using R^2.\n",
    "# Train R^2\n",
    "print(\"Trainng R^2: %f\" % lasso.score(X_train_scaled, y_train))\n",
    "# Test R^2\n",
    "print(\"Test R^2: %f\" % lasso.score(X_test_scaled, y_test))\n",
    "\n",
    "# Number of coefficients != 0 will tell us how many features are being used\n",
    "features_used = lasso.coef_ != 0\n",
    "print(\"Number of features being used: %d\" % np.sum(features_used))\n",
    "\n",
    "print(\"Names of features being used:\")\n",
    "for feature, used in zip(all_features, features_used):\n",
    "    if used:\n",
    "        print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Answers\n",
    "* Training R<sup>2</sup> = 0.534242\n",
    "* Test R<sup>2</sup> = 0.419899\n",
    "* No. of features used = 7 (out of 10)\n",
    "* Names of features being used:\n",
    "    * sex\n",
    "    * bmi\n",
    "    * bp\n",
    "    * s1\n",
    "    * s3\n",
    "    * s4\n",
    "    * s5\n",
    "    \n",
    "The performance of lasso on this preprocessed dataset is closer to that of [6] as opposed to [3]. This goes against the expectation that it would be closer to the results for the normalised data from [3]. This could be because this dataset and the dataset used in [3] were normalised in different ways. \n",
    "\n",
    "This dataset uses ```StandardScaler```, which makes the mean of each feature 0 and its standard deviation 1. The dataset from [3] however normalises it by doing the following (according to the DESCR):\n",
    "\n",
    "> \"Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot Test R<sup>2</sup> against number of features used for varying values of the α parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.031250 . Test R^2: 0.419980 . Features used: 10 \n",
      "Alpha: 0.062500 . Test R^2: 0.420708 . Features used: 10 \n",
      "Alpha: 0.125000 . Test R^2: 0.421665 . Features used: 10 \n",
      "Alpha: 0.250000 . Test R^2: 0.420145 . Features used: 10 \n",
      "Alpha: 0.500000 . Test R^2: 0.419872 . Features used: 9 \n",
      "Alpha: 1.000000 . Test R^2: 0.419899 . Features used: 7 \n",
      "Alpha: 2.000000 . Test R^2: 0.416763 . Features used: 6 \n",
      "Alpha: 4.000000 . Test R^2: 0.402941 . Features used: 5 \n",
      "Alpha: 8.000000 . Test R^2: 0.396487 . Features used: 4 \n",
      "Alpha: 16.000000 . Test R^2: 0.374059 . Features used: 3 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11093d2b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores = []\n",
    "features_used = []\n",
    "alpha_values = [2 ** k for k in range(-5, 5)]\n",
    "\n",
    "for a in alpha_values:\n",
    "    \n",
    "    lasso = Lasso(alpha=a).fit(X_train_scaled, y_train)\n",
    "    test_score = lasso.score(X_test_scaled, y_test)\n",
    "    features = np.sum(lasso.coef_ != 0)\n",
    "    \n",
    "    print(\"Alpha: %f . Test R^2: %f . Features used: %d \" % (a, test_score, features))\n",
    "\n",
    "    test_scores.append(test_score)\n",
    "    features_used.append(features)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(17, 7))\n",
    "\n",
    "for i in range(len(test_scores)):\n",
    "    plt.scatter(test_scores[i], features_used[i], label=alpha_values[i])\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), title='alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot, we can see that the larger the α value, the poorer the performance (as we get smaller values for Test R<sup>2</sup>).\n",
    "\n",
    "I had initially used α = 2<sup>k</sup> for k in [-5, -4, ..., 4, 5], however, k=5 gave an α of 32, with Test R<sup>2</sup> = 0.238489 and Features used = 2. This score was significantly lower than the others, so I did not use this value and stopped at k=4.\n",
    "\n",
    "If we don't want to use all the features, a good α would be 2. I prefer this one because it's performance is close to that of others with a lower α, while it only uses 6 features(so it has a good balance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Choose the regularisation parameter for the Lasso using cross-validation on the training set\n",
    "\n",
    "By using ```GridSearchCV``` on Lasso with a range of values for the α parameter, we can find the best choice for α."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'alpha': 2}\n",
      "Best cross-validation accuracy:  0.5098536654307827\n",
      "Trainng R^2: 0.529743\n",
      "Test R^2: 0.416763\n",
      "Number of features being used: 6\n",
      "Names of features being used:\n",
      "sex\n",
      "bmi\n",
      "bp\n",
      "s1\n",
      "s3\n",
      "s5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { 'alpha': [2 ** k for k in range(-5, 6)] }\n",
    "grid_search = GridSearchCV(Lasso(), param_grid, cv=5, iid=True)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
    "\n",
    "# Gives the model with the best parameters, trained on the whole training set \n",
    "best_lasso = grid_search.best_estimator_\n",
    "\n",
    "print(\"Trainng R^2: %f\" % best_lasso.score(X_train_scaled, y_train))\n",
    "print(\"Test R^2: %f\" % best_lasso.score(X_test_scaled, y_test))\n",
    "\n",
    "features_used = best_lasso.coef_ != 0\n",
    "print(\"Number of features being used: %d\" % np.sum(features_used))\n",
    "\n",
    "print(\"Names of features being used:\")\n",
    "for feature, used in zip(all_features, features_used):\n",
    "    if used:\n",
    "        print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Answers\n",
    "* Training R<sup>2</sup> = 0.529743\n",
    "* Test R<sup>2</sup> = 0.416763\n",
    "* No. of features used = 6 (out of 10)\n",
    "* Names of features being used:\n",
    "    * sex\n",
    "    * bmi\n",
    "    * bp\n",
    "    * s1\n",
    "    * s3\n",
    "    * s5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Implement an Inductive Conformal Predictor\n",
    "\n",
    "> a) Split the training set that you obtained in item **5** into two parts: the ***calibration set of size 99*** and the ***rest of the training set*** (the ***training set proper***)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 10) (232, 10) (99,) (232,)\n"
     ]
    }
   ],
   "source": [
    "# X_train and y_train are the training sets from item 5\n",
    "X_train_pr, X_calibration, y_train_pr, y_calibration = train_test_split(X_train, y_train, test_size=99, random_state=308)\n",
    "\n",
    "print(X_calibration.shape, X_train_pr.shape, y_calibration.shape, y_train_pr.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Preprocess the ***training set proper, calibration set,*** and ***test set*** in the same way using ```StandardScaler```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our scaler\n",
    "s = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training set proper\n",
    "s.fit(X_train_pr)\n",
    "\n",
    "# Apply same scaler to training set proper, calibration set, and test set to preprocess them in the same way\n",
    "X_train_pr_scaled = s.transform(X_train_pr)\n",
    "X_calibration_scaled = s.transform(X_calibration)\n",
    "X_test_scaled = s.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c) Using the nonconformity measure α = |y − yˆ|, where y is the true label and yˆ is its prediction given the training set proper, for each test sample compute the prediction interval for it. Do this for significance levels 5% and 20%. For each of these significance levels compute:\n",
    "* the length of the prediction intervals for the test samples\n",
    "* and the test error rate of your inductive conformal predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5% Confidence level:\n",
      "\tInterval Length: 180.514327\n",
      "\tTest Error Rate: 0.117117\n",
      "20% Confidence level:\n",
      "\tInterval Length: 117.188962\n",
      "\tTest Error Rate: 0.378378\n"
     ]
    }
   ],
   "source": [
    "# Fit lasso to training set proper\n",
    "lasso = Lasso(alpha=2).fit(X_train_pr_scaled, y_train_pr)\n",
    "\n",
    "# Get the lasso predictions for our calibration set\n",
    "predicted_values_calibration = lasso.predict(X_calibration_scaled)\n",
    "\n",
    "# Compute α = |y − yˆ|, where y is the true label and yˆ is its prediction.\n",
    "non_conformity_scores = [ abs(true - pred) \n",
    "                         for true, pred \n",
    "                         in zip(y_calibration, predicted_values_calibration) ]\n",
    "\n",
    "\n",
    "sorted_non_conformities = non_conformity_scores.copy()\n",
    "sorted_non_conformities.sort()\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "# Calculate k and c for 5% and 20% significance level\n",
    "\n",
    "k5 = ceil( (1 - 0.05) * (len(X_calibration_scaled) + 1) )\n",
    "c5 = sorted_non_conformities[k5-1]\n",
    "\n",
    "k20 = ceil( (1 - 0.2) * (len(X_calibration_scaled) + 1) )\n",
    "c20 = sorted_non_conformities[k20-1]\n",
    "\n",
    "predicted_values_test = lasso.predict(X_test_scaled)\n",
    "\n",
    "prediction_intervals_5 = []\n",
    "prediction_intervals_20 = []\n",
    "correct_5 = []\n",
    "correct_20 = []\n",
    "\n",
    "for sample, true_label, predicted_label in zip(X_test_scaled, y_test, predicted_values_test):\n",
    "    \n",
    "    # Calculate prediction interval for test sample\n",
    "    pred_interval_5 = [ predicted_label - c5, predicted_label + c5 ]\n",
    "    pred_interval_20 = [ predicted_label - c20, predicted_label + c20 ]\n",
    "    \n",
    "    prediction_intervals_5.append(pred_interval_5)\n",
    "    prediction_intervals_20.append(pred_interval_20)\n",
    "    \n",
    "    # Inductive conformal predictor is only correct if true label is coved by prediction interval.\n",
    "    prediction_correct_5 = pred_interval_5[0] <= true_label <= pred_interval_5[1]\n",
    "    prediction_correct_20 = pred_interval_20[0] <= true_label <= pred_interval_20[1]\n",
    "    \n",
    "    correct_5.append(prediction_correct_5)\n",
    "    correct_20.append(prediction_correct_20)\n",
    "    \n",
    "    \n",
    "# Using our definition of a predition set, all prediction sets are of the same length. \n",
    "# This means we can check the length of any of the prediction intervals.\n",
    "length_interval_5 = np.diff(prediction_intervals_5[0])\n",
    "length_interval_20 = np.diff(prediction_intervals_20[0])\n",
    "\n",
    "# Test error rate = number of errors made / total number of test samples\n",
    "# Since the value we have is the number of correct prediction itervals, we subtract it from 1 to get the error rate.\n",
    "test_error_rate_5 = 1 - np.mean(correct_5)\n",
    "test_error_rate_20 = 1 - np.mean(correct_20)\n",
    "\n",
    "print(\"5% Confidence level:\")\n",
    "print(\"\\tInterval Length: %f\" % length_interval_5)\n",
    "print(\"\\tTest Error Rate: %f\" % test_error_rate_5)\n",
    "print(\"20% Confidence level:\")\n",
    "print(\"\\tInterval Length: %f\" % length_interval_20)\n",
    "print(\"\\tTest Error Rate: %f\" % test_error_rate_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Results\n",
    "\n",
    "> ### a) The training and test R<sup>2</sup> for the Lasso model with default parameters on the ```scikit-learn``` version of diabetes and the number of features used.\n",
    "\n",
    "Training R<sup>2</sup> = 0.392352\n",
    "\n",
    "Test R<sup>2</sup> = 0.343602\n",
    "\n",
    "No. of features used = 3 (out of 10)\n",
    "\n",
    "Names of features being used:\n",
    "* bmi\n",
    "* bp\n",
    "* s5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### b) The training and test R<sup>2</sup> for the Lasso model with default parameters on the original version of diabetes and the number of features used.\n",
    "\n",
    "\n",
    "Training R<sup>2</sup> = 0.532342\n",
    "\n",
    "Test R<sup>2</sup> = 0.423408\n",
    "\n",
    "No. of features used = 9 (out of 10)\n",
    "\n",
    "Names of features being used:\n",
    "* age\n",
    "* sex\n",
    "* bmi\n",
    "* bp\n",
    "* s2\n",
    "* s3\n",
    "* s4\n",
    "* s5\n",
    "* s6\n",
    "    \n",
    "The performance of lasso on this dataset is better than the one from the ```scikit-learn``` version, which can be see from the higher R<sup>2</sup> values for the training and test sets. We can also see that for the current dataset almost all of the features are being used, whereas very few were used in the previous one (9 out of 10 are being used for the current dataset, while only 3 out of 10 were used in the previous one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### c) The training and test R<sup>2</sup> for the Lasso model with default parameters on your version of diabetes (i.e., on the original version of diabetes with the features normalized by you); the number of features used.\n",
    "\n",
    "\n",
    "Training R<sup>2</sup> = 0.534242\n",
    "\n",
    "Test R<sup>2</sup> = 0.419899\n",
    "\n",
    "No. of features used = 7 (out of 10)\n",
    "\n",
    "Names of features being used:\n",
    "* sex\n",
    "* bmi\n",
    "* bp\n",
    "* s1\n",
    "* s3\n",
    "* s4\n",
    "* s5\n",
    "\n",
    "The performance of lasso on this preprocessed dataset is closer to that of [6] as opposed to [3]. This goes against the expectation that it would be closer to the results for the normalised data from [3]. This could be because this dataset and the dataset used in [3] were normalised in different ways. \n",
    "\n",
    "This dataset uses ```StandardScaler```, which makes the mean of each feature 0 and its standard deviation 1. The dataset from [3] however normalises it by doing the following (according to the DESCR):\n",
    "\n",
    "> \"Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### d) The training and test R<sup>2</sup> for the Lasso model with the best parameters chosen by cross-validation on your version of diabetes; the number of features used.\n",
    "\n",
    "\n",
    "Training R<sup>2</sup> = 0.529743\n",
    "\n",
    "Test R<sup>2</sup> = 0.416763\n",
    "\n",
    "No. of features used = 6 (out of 10)\n",
    "\n",
    "Names of features being used:\n",
    "* sex\n",
    "* bmi\n",
    "* bp\n",
    "* s1\n",
    "* s3\n",
    "* s5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### e) The lengths of prediction intervals and their test error rates at significance levels 5% and 20% (if you are implementing an inductive conformal predictor).\n",
    "\n",
    "\n",
    "5% Confidence level:\n",
    "* Interval Length: 180.514327\n",
    "* Test Error Rate: 0.117117 ( = 11.71% )\n",
    "\n",
    "20% Confidence level:\n",
    "* Interval Length: 117.188962\n",
    "* Test Error Rate: 0.378378 ( = 37.84% )\n",
    "\n",
    "While 5% has a lower test error rate than 20%, it also has a greater interval length."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
